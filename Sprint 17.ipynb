{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feed7b6d",
   "metadata": {},
   "source": [
    "Capítulo 2 - Lección 3:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Entrena un modelo de regresión lineal con las herramientas de Keras. Utiliza el método fit() para imprimir el progreso del entrenamiento y el valor del error. Para obtener un formato de respuesta conveniente, agrega el argumento verbose=2 al método. Si estableces este argumento en 0, no se imprimirá ninguna respuesta. Establece el argumento en 2 para obtener la salida para Jupyter Notebook.\n",
    "\n",
    "Las dos primeras líneas se agregaron para limpiar las advertencias que no están relacionadas con nuestra tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3162dbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features, target, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab24b57",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Elige un número de épocas (es decir, cuántas veces han pasado nuestros datos a través del algoritmo) para que el ECM sea inferior a 6.55. Puedes agregar épocas especificando el argumento epochs para el método model.fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d093",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(features, target, verbose=2, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8bce66",
   "metadata": {},
   "source": [
    "Ejercicio 3:\n",
    "\n",
    "\n",
    "Encuentra el valor de la función de pérdida para el conjunto de validación. Pasa el conjunto de validación al modelo a través del argumento validation_data del método model.fit().\n",
    "\n",
    "Ya hemos cargado el conjunto de validación (está en el precódigo) y dividido en dos subconjuntos: uno para las características (features_valid) y otro para los objetivos (target_valid). Tu objetivo es pasar (features_valid, target_valid) como un valor para el argumento validation_data.\n",
    "\n",
    "Se requiere pasar el mismo número de épocas que estaban en la tarea anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c08d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "data_train = pd.read_csv('/datasets/train_data_n.csv')\n",
    "features_train = data_train.drop('target', axis=1)\n",
    "target_train = data_train['target']\n",
    "\n",
    "data_valid = pd.read_csv('/datasets/test_data_n.csv')\n",
    "features_valid = data_valid.drop('target', axis=1)\n",
    "target_valid = data_valid['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units=1, input_dim=features_train.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=5,\n",
    "    validation_data=(features_valid, target_valid),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad00ab0",
   "metadata": {},
   "source": [
    "Lección 5:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Entrena la regresión logística utilizando los datos cargados en el precódigo. Establece el número de épocas en cinco.\n",
    "\n",
    "Para imprimir el progreso del entrenamiento, especifica verbose=2 para fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61438d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=1, input_dim=features_train.shape[1], activation='sigmoid'\n",
    "    )\n",
    ")\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=5,\n",
    "    verbose=2,\n",
    "    validation_data=(features_valid, target_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd155b",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Encuentra la exactitud del modelo utilizando el conjunto de validación. Calcula las predicciones con la función predict(), al igual que en sklearn. Sigmoide devolverá números de 0 a 1. Convierte los números resultantes en clases en comparación con 0.5.\n",
    "\n",
    "Imprime el valor de exactitud (en el precódigo). Especifica verbose=0 para deshacerte de la salida del progreso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f2a83",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=1, input_dim=features_train.shape[1], activation='sigmoid'\n",
    "    )\n",
    ")\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=5,\n",
    "    verbose=0,\n",
    "    validation_data=(features_valid, target_valid),\n",
    ")\n",
    "\n",
    "\n",
    "# Realiza las predicciones sobre el conjunto de validación\n",
    "predicted_probs = model.predict(features_valid)\n",
    "\n",
    "# Convierte las probabilidades en clases (0 o 1) usando el umbral de 0.5\n",
    "predicted_classes = (predicted_probs > 0.5).astype(int)\n",
    "\n",
    "# Calcula la exactitud usando sklearn\n",
    "accuracy = accuracy_score(target_valid, predicted_classes)\n",
    "\n",
    "# Imprime el resultado\n",
    "print('Exactitud:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039ca60",
   "metadata": {},
   "source": [
    "Ejercicio 3:\n",
    "\n",
    "Por lo general, entrenar una red neuronal lleva mucho tiempo. Modifiquemos el modelo para que podamos rastrear su calidad en cada época: agrega el parámetro metrics=['acc'] (exactitud) al método compile().\n",
    "\n",
    "Entrena el modelo, usando diez épocas para mejorar la exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71cca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=1, input_dim=features_train.shape[1], activation='sigmoid'\n",
    "    )\n",
    ")\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_data=(features_valid, target_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9ba50",
   "metadata": {},
   "source": [
    "Lección 8:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Agrega otra capa a la red neuronal. Deja que la primera capa oculta tenga diez neuronas (units) con activación sigmoide. La segunda capa de salida tendrá una neurona con un sigmoide y la consideraremos en la probabilidad de la clase \"1\".\n",
    "\n",
    "Usa diez épocas para entrenar la red neuronal. Imprime el progreso del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a63099",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/datasets/train_data_n.csv')\n",
    "df['target'] = (df['target'] > df['target'].median()).astype(int)\n",
    "features_train = df.drop('target', axis=1)\n",
    "target_train = df['target']\n",
    "\n",
    "df_val = pd.read_csv('/datasets/test_data_n.csv')\n",
    "df_val['target'] = (df_val['target'] > df['target'].median()).astype(int)\n",
    "features_valid = df_val.drop('target', axis=1)\n",
    "target_valid = df_val['target']\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units = 10, activation = 'sigmoid', input_dim = features_train.shape[1]))\n",
    "model.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "\n",
    "model.fit(features_train, \n",
    "          target_train, \n",
    "          epochs=10, \n",
    "          verbose=2,\n",
    "          validation_data=(features_valid, target_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528abda",
   "metadata": {},
   "source": [
    "Lección 9:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Llama a plt.imshow() (muestra de imagen) para trazar la imagen. No necesitas especificar ningún otro argumento (que no sea array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80747cec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac6ad3",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Observa la función imshow() y agrega el argumento que establecerá el mapa de color en blanco y negro. Luego agrega la barra de color a la imagen llamando a colorbar():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443a10c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "plt.imshow(array, cmap = 'gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82b546",
   "metadata": {},
   "source": [
    "Ejercicio 3:\n",
    "\n",
    "Repinta de negro la esquina superior izquierda de la imagen (0), y blanquea la esquina inferior derecha blanca (255). Puedes trabajar con una imagen como lo harías con una matriz bidimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c3c7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "array[0, 0] = 0\n",
    "array[14, 12] = 255\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734bfc03",
   "metadata": {},
   "source": [
    "Ejercicio 4:\n",
    "\n",
    "Por lo general, las redes neuronales aprenden mejor cuando reciben imágenes en el rango de 0 a 1 como entrada.\n",
    "\n",
    "Convierte la escala [0, 255] a [0, 1]. Para hacer esto, divide todos los valores de la matriz bidimensional entre 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb34e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/face.png')\n",
    "array = np.array(image)\n",
    "\n",
    "array = array / 255\n",
    "\n",
    "plt.imshow(array, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702834c6",
   "metadata": {},
   "source": [
    "Lección 10:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Asegúrate de que los canales se almacenen en la tercera coordenada. Para hacer esto, imprime el tamaño de la matriz obtenida de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7148ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a1d48",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Imprime solo el canal rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787a0fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open('/datasets/ds_cv_images/cat.jpg')\n",
    "array = np.array(image)\n",
    "\n",
    "red_channel = array[:, :, 0]\n",
    "\n",
    "plt.imshow(red_channel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829b06d",
   "metadata": {},
   "source": [
    "Lección 12:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Echa un vistazo a los datos: Ya cargamos las muestras y dividimos todo en características y el objetivo. Tus objetivos son:\n",
    "\n",
    "Imprime los tamaños de características para ambas muestras.\n",
    "Luego imprime el valor objetivo para la primera imagen de la muestra de entrenamiento.\n",
    "Imprime la imagen en blanco y negro. (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7db423",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(features_train, target_train), (features_test, target_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Train:\", features_train.shape)\n",
    "print(\"Test:\", features_test.shape)\n",
    "\n",
    "print(\"First image class:\", target_train[0])\n",
    "plt.imshow(features_train[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde2650",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "En una red totalmente conectada, las observaciones de entrada deben ser las filas de la tabla y todo el conjunto de datos debe ser una tabla bidimensional. Para evitar errores, transforma el conjunto de datos de una matriz tridimensional en una tabla bidimensional. Para hacerlo, utiliza el método np.array.reshape().\n",
    "\n",
    "Modifica features_train para que el primer valor de features_train.shape almacene la cantidad de observaciones y el segundo valor almacene la cantidad de pixeles en la imagen. Realiza lo mismo para features_test. Imprime los nuevos tamaños de las matrices (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e975c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(features_train, target_train), (features_test, target_test) = fashion_mnist.load_data()\n",
    "\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "print(\"Train:\", features_train.shape)\n",
    "print(\"Test:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ec6a8",
   "metadata": {},
   "source": [
    "Ejercicio 3:\n",
    "\n",
    "Construye y entrena una red neuronal. Primero, crea una regresión logística con diez clases en Keras.\n",
    "\n",
    "Necesitarás:\n",
    "\n",
    "La función de activación 'softmax'\n",
    "La función de pérdida 'sparse_categorical_crossentropy'\n",
    "La palabra \"sparse\" (disperso) indica la técnica utilizada para la codificación de respuestas. En nuestra tarea, solo necesitamos el número de clases, por lo que elegimos esta función de pérdida.\n",
    "\n",
    "Si las respuestas están codificadas con codificación one-hot y la clase 9 corresponde al vector completo [0, 0, 0, 0, 0, 0, 0, 0, 1], entonces se usa la función categorical_crossentropy().\n",
    "\n",
    "Entrena la red con una época. Imprime el progreso del entrenamiento y los valores de exactitud para las muestras de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d3306",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(features_train, target_train), (features_test, target_test) = fashion_mnist.load_data()\n",
    "\n",
    "features_train = features_train.reshape(features_train.shape[0], 28 * 28)\n",
    "features_test = features_test.reshape(features_test.shape[0], 28 * 28)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(units=10, input_dim=28 * 28, activation='softmax')\n",
    ")\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc']\n",
    ")\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=1,\n",
    "    verbose=2,\n",
    "    validation_data=(features_test, target_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5b684",
   "metadata": {},
   "source": [
    "Capítulo 3: Lección 4:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Al final del capítulo anterior, entrenaste una red neuronal completamente conectada para clasificar ropa. Reemplázala con una red convolucional con estas capas: Conv2D + Flatten + Dense. Usa cuatro filtros de 3x3 en la capa convolucional y \"relu\" como función de activación. No especifiques nada dentro de la capa Flatten. Determina el output de la capa Dense como 10 unidades y usa el \"softmax\".\n",
    "\n",
    "No necesitas entrenar la red. Llama a la función summary(), que mostrará en pantalla su información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c899cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "# Cambia las dimensiones de la imagen y establece el rango de [0, 1].\n",
    "# Al cambiar el tamaño, puedes configurar una de las dimensiones a -1\n",
    "# para que se calcule automáticamente\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc']\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=4,\n",
    "        kernel_size=(3, 3),\n",
    "        activation=\"relu\",\n",
    "        input_shape=(28, 28, 1),\n",
    "    )\n",
    ")\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97636d",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Agrega otra capa convolucional con cuatro filtros de 3x3 a la red. Determina los parámetros para que el tamaño de la imagen permanezca igual después de la primera capa pero disminuya a la mitad después de la segunda.\n",
    "\n",
    "Llama a la función summary() para mostrar la estructura de la red y luego entrena un objeto para ver si el código funciona (ya en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2a23b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Primera capa Conv2D (mantiene tamaño: 28x28 → 28x28)\n",
    "model.add(Conv2D(4, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Segunda capa Conv2D (reduce tamaño: 28x28 → 14x14)\n",
    "model.add(Conv2D(4, (3, 3), activation='relu', padding='same', strides=2))\n",
    "\n",
    "# Aplanar y salida\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=1,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece278d5",
   "metadata": {},
   "source": [
    "Capítulo 3 - Leción 5:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Agrega Max Pooling con un tamaño de 2x2 después de las capas convolucionales. Llama a la función summary() para ver cómo ha cambiado el número de parámetros.\n",
    "\n",
    "Asegúrate que el código funciona entrenando un objeto individual (ya en el precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f60b87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=4,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation=\"relu\",\n",
    "        input_shape=(28, 28, 1),\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=4,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=1,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22eab4f",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Después de estudiar la descripción que la función summary() muestra, vas a crear una arquitectura LeNet:\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Capa (tipo)                Forma de output              Parám #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
    "_________________________________________________________________\n",
    "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
    "_________________________________________________________________\n",
    "average_pooling2d_1 (Promedio (None, 5, 5, 16)          0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 400)               0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 120)               48120     \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 84)                10164     \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 10)                850       \n",
    "=================================================================\n",
    "La función de activación en todas las capas está establecida en tangente hiperbólica, con excepción de la última. Las redes con este tipo de activación entrenan más eficazmente que las que tienen sigmoid. Solo relu puede superar a 'tanh', pero no se usaba cuando se estaba desarrollando LeNet. Usa el tamaño de kernel/pooling y el padding para obtener las dimensiones deseadas. \n",
    "\n",
    "Llama a la función summary(). Entrena un objeto para asegurarte que el código funciona (ya en el precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e8843",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "features_train = np.load('/datasets/fashion_mnist/train_features.npy')\n",
    "target_train = np.load('/datasets/fashion_mnist/train_target.npy')\n",
    "features_test = np.load('/datasets/fashion_mnist/test_features.npy')\n",
    "target_test = np.load('/datasets/fashion_mnist/test_target.npy')\n",
    "\n",
    "\n",
    "features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "features_test = features_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, (5, 5), padding='same', activation='tanh',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (5, 5), padding='valid', activation='tanh'))\n",
    "model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='tanh'))\n",
    "\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['acc']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=1,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546cde2",
   "metadata": {},
   "source": [
    "Capítulo 3 - Lección 7:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Hay una red convolucional en el precódigo. Escribe el código para que puedas pasarle el conjunto de datos de frutas para el entrenamiento y la validación.\n",
    "\n",
    "Para acortar el tiempo de entrenamiento, llama a fit() con steps_per_epoch=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230237b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "    \n",
    "datagen = ImageDataGenerator(validation_split=0.25)\n",
    "\n",
    "train_datagen_flow = datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=12345,\n",
    ")\n",
    "\n",
    "val_datagen_flow = datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=12345,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=6,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(150, 150, 3),\n",
    "    )\n",
    ")\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=12, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc']\n",
    ")\n",
    "\n",
    "model.fit(train_datagen_flow,\n",
    "          validation_data=val_datagen_flow,\n",
    "          steps_per_epoch=1,\n",
    "          validation_steps=1,\n",
    "          verbose=2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a0c8c",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Comienza preprocesando los datos: divide los valores de brillo entre 255. Para hacer esto, pasa un argumento especial a ImageDataGenerator, que configurará el divisor en 255 (encuéntralo en la documentación).\n",
    "\n",
    "No necesitarás crear ni entrenar el modelo. Imprime los valores de pixel de la imagen del primer lote del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925c655",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "datagen = ImageDataGenerator(validation_split=0.25, rescale = 1./255)\n",
    "\n",
    "train_datagen_flow = datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=12345)\n",
    "\n",
    "val_datagen_flow = datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=12345)\n",
    "\n",
    "features, target = next(train_datagen_flow)\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e62c2",
   "metadata": {},
   "source": [
    "Capítulo 3 - Lección 9:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Haz aumentos en el conjunto de entrenamiento (train_datagen) con estas operaciones:\n",
    "\n",
    "Reflejo vertical y horizontal.\n",
    "Rotaciones de hasta 90 grados.\n",
    "Aumento vertical y horizontal de las imágenes de hasta 20% de su tamaño original.\n",
    "Crea un generador para el conjunto de validación (valid_datagen).\n",
    "\n",
    "Muestra las imágenes del primer lote en el conjunto de entrenamiento. El código para un output condensado de 16 imágenes ya está en el precódigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0fe4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.25,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=90)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    validation_split=0.25,\n",
    "    rescale=1./255)\n",
    "\n",
    "train_datagen_flow = train_datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=12345)\n",
    "\n",
    "val_datagen_flow = validation_datagen.flow_from_directory(\n",
    "    '/datasets/fruits_small/',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=12345)\n",
    "\n",
    "features, target = next(train_datagen_flow)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    fig.add_subplot(4, 4, i+1)\n",
    "    plt.imshow(features[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
