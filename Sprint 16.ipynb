{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db044a7d",
   "metadata": {},
   "source": [
    "Capítulo 2 - Leccción 2:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Escribe la función lemmatize(text) usando la librería spaCy. Esta debería convertir el texto a minúsculas y lematizarlo, devolviendo una cadena lematizada. Puedes tomar cualquier registro aleatorio del conjunto de datos. Si te parece que son demasiado largos (después de todo, ¡son reseñas!), utiliza el registro de texto No. 2557 (este es una reseña breve) de imdb_reviews_small.tsv. Imprime tanto el texto inicial como el lematizado (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random             # para seleccionar una reseña aleatoria\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small.tsv', sep='\\t')\n",
    "corpus = data['review']\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text\n",
    "\n",
    "review_idx = random.randint(0, len(corpus)-1)\n",
    "\n",
    "review = corpus[review_idx]\n",
    "\n",
    "print('El texto original:', review)\n",
    "print()\n",
    "print('El texto lematizado:', lemmatize(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bf37d",
   "metadata": {},
   "source": [
    "Lección 3:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Escribe la función clear_text(text) para mantener solo letras latinas, espacios y apóstrofos en el texto. También elimina cualquier espacio adicional. La función tomará el texto inicial y devolverá el texto después de limpiarlo.\n",
    "\n",
    "Imprime el texto inicial y el texto después de la limpieza y lematización (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33541796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  # para seleccionar una reseña aleatoria\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small.tsv', sep='\\t')\n",
    "corpus = data['review']\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "\n",
    "    clean_text = re.sub(r'[^a-zA-z\\']', ' ', text)\n",
    "    clean_text = \" \".join(clean_text.split())\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_)\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "\n",
    "# guarda el índice de revisión en la variable review_idx\n",
    "# ya sea como un número aleatorio o un valor fijo, por ejemplo, 2557\n",
    "review_idx = random.randint(0, len(corpus) - 1)\n",
    "# review_idx = 2557\n",
    "\n",
    "review = corpus[review_idx]\n",
    "\n",
    "print('El texto original:', review)\n",
    "print()\n",
    "print('El texto lematizado:', lemmatize(clear_text(review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2692854",
   "metadata": {},
   "source": [
    "Lección 5:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "imdb_reviews_small_lemm.tsv contiene el conjunto de datos imdb_reviews_small.tsv al que agregamos la columna review_lemm con reseñas limpias y lematizadas.\n",
    "\n",
    "Crea dos bolsas de palabras para el corpus de reseñas: con y sin palabras vacías. Imprime sus tamaños (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23821ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small_lemm.tsv', sep='\\t')\n",
    "corpus = data['review_lemm']\n",
    "\n",
    "# crea una bolsa de palabras con la comprobación de las palabras vacías\n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(corpus)\n",
    "\n",
    "print('El tamaño de BoW con palabras vacías:', bow.shape)\n",
    "\n",
    "# crea una bolsa de palabras con la comprobación de palabras vacías\n",
    "stop_words = set(stopwords.words('english'))\n",
    "count_vect = CountVectorizer(stop_words=stop_words)\n",
    "bow = count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ad6a1",
   "metadata": {},
   "source": [
    "Ejercicio 2:\n",
    "\n",
    "Crea un contador de n-gramas para el corpus de reseñas. Cada frase debe tener dos palabras. Imprime el tamaño del n-grama (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small_lemm.tsv', sep='\\t')\n",
    "corpus = data['review_lemm']\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range = (2,2))\n",
    "n_gram = count_vect.fit_transform(corpus)\n",
    "\n",
    "print('El tamaño del bigrama:', n_gram.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd76dfa",
   "metadata": {},
   "source": [
    "Lección 7:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Crea una matriz con valores TF-IDF para el corpus de reseñas. Guárdala en la variable tf_idf. Imprime el tamaño de la matriz (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small_lemm.tsv', sep='\\t')\n",
    "corpus = data['review_lemm']\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words)\n",
    "tf_idf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print('El tamaño de la matriz TF-IDF:', tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6c253",
   "metadata": {},
   "source": [
    "Lección 8:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "Tu objetivo ahora es entrenar una regresión logística para determinar la tonalidad de las reseñas.\n",
    "\n",
    "Tanto el dataset de entrenamiento como el conjunto de datos de prueba ya se han leído en el precódigo. Esto es lo que te pedimos que hagas:\n",
    "\n",
    "Extrae reseñas lematizadas que se utilizarán para propósitos de entrenamiento y guárdalos en la variable train_corpus. Es importante observar que las reseñas lematizadas están en la columna review_lemm del dataset, así que no tendrás que lematizar reseñas por tu cuenta.\n",
    "Establece las palabras vacías y guárdalas en la variable stop_words.\n",
    "Inicializa el TF_IDF vectorizer y guárdalo en la variable count_tf_idf.\n",
    "Ajusta y transforma el corpus de entrenamiento, y guarda los resultados en la variable tf_idf.\n",
    "Las características que se usarán para el entrenamiento son los valores almacenados en la variable tf idf, así que establece features train en ella.\n",
    "Los objetivos se encuentran en la columna pos del conjunto de datos (0 - reseña negativa, 1 - reseña positiva). Extrae los objetivos para fines de entrenamientos utilizando el nombre de la columna y guárdalos en la variable target_train.\n",
    "Al igual que en el primer punto, extrae las reseñas lematizadas para probarlas y guárdalas en la variable test_corpus.\n",
    "Obtén las características para probar transformando las reseñas lematizadas utilizando TF_IDF vectorizer, que utilizaste para el entrenamiento. Almacena los resultados de la transformación en la variable features_test.\n",
    "Inicializa el modelo de regresión logística en la variable model y ajústalo con las características de entrenamiento y los objetivos.\n",
    "Obtén predicciones para las características de prueba y almacénalos en la variable pred_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d67448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_data = pd.read_csv('/datasets/imdb_reviews_small_lemm_train.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('/datasets/imdb_reviews_small_lemm_test.tsv', sep='\\t')\n",
    "\n",
    "train_corpus = train_data['review_lemm']\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf = count_tf_idf.fit_transform(train_corpus)\n",
    "\n",
    "features_train = tf_idf\n",
    "target_train = train_data['pos']\n",
    "\n",
    "test_corpus = test_data['review_lemm']\n",
    "features_test = count_tf_idf.transform(test_corpus)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(features_train, target_train)\n",
    "pred_test = model.predict(features_test)\n",
    "\n",
    "submission = pd.DataFrame({'pos':pred_test})\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
